
üéí Welcome to Day 1: Foundational Large Language Models & Prompt Engineering
----


Hello Learner,

**1. Complete the Intro Unit ‚Äì ‚ÄúFoundational Large Language Models & Text Generation‚Äù:**

- Listen to the [summary podcast episode](https://www.youtube.com/watch?v=Na3O4Pkbp-U&list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE&index=2) for this unit.
- To complement the podcast, read the [‚ÄúFoundational Large Language Models & Text Generation‚Äù](https://drive.google.com/file/d/1rYu-mIcsTrAeCuH-xHPofrI1i1qNVzqO/view) whitepaper. 

**2. Complete Unit 1 ‚Äì ‚ÄúPrompt Engineering‚Äù:**

- Listen to the [summary podcast episode](https://www.youtube.com/watch?v=CFtX0ZyLSAY&list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE&index=3) for this unit.
- To complement the podcast, read the [‚ÄúPrompt Engineering‚Äù](https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view) whitepaper.
- Complete these codelabs on Kaggle:
     - [Prompting fundamentals](https://www.kaggle.com/code/markishere/day-1-prompting)
     - [Evaluation and structured data](https://www.kaggle.com/code/markishere/day-1-evaluation-and-structured-output)
- Make sure you [phone verify your Kaggle account](https://www.kaggle.com/settings) before starting, it's necessary for the codelabs.
- Want to have an [interactive conversation?](https://support.google.com/notebooklm/answer/15731776?hl=en&ref_topic=14272601&sjid=16012842710481496794-EU) Try adding the whitepapers to [NotebookLM](https://notebooklm.google.com/).

  
üí° What You‚Äôll Learn
---

Today you‚Äôll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You‚Äôll also get trained in the art of prompt engineering for optimal LLM interaction and evaluating LLMs. 

The first codelab will walk you through getting started with the Gemini 2.0 API and cover several prompt techniques including how different parameters impact the prompts. In the second codelab, you will also learn how to evaluate the response of LLMs using autoraters and structured output.

Happy Learning!
